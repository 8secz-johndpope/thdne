{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2_Tazik_25GB_RAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZKTKZ/thdne/blob/master/StyleGAN2_Tazik_25GB_RAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR8n0yeImPCx",
        "colab_type": "text"
      },
      "source": [
        "## Colab Hacks\n",
        "\n",
        "Induce Colab RAM -> 25gb\n",
        "\n",
        "\n",
        "```\n",
        "i = []\n",
        "while True:\n",
        "  i.append(i)\n",
        "```\n",
        "\n",
        "Keep Colab from disconnecting after 1.5hrs.\n",
        "\n",
        "```\n",
        "\n",
        "function KeepClicking(){\n",
        "   console.log(\"Clicking\");\n",
        "   document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(KeepClicking,60000)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE5GqZHcHHBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "0753d0b6-12fd-4206-da90-d3abdc0d692e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/ZKTKZ/stylegan2.git\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))\n",
        "\n",
        "!pip install tensorboard\n",
        "\n",
        "url = 'https://drive.google.com/open?id=1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez'\n",
        "#'https://drive.google.com/open?id=1BHeqOZ58WZ-vACR2MJkh1ZVbJK2B-Kle'\n",
        "model_id = url.replace('https://drive.google.com/open?id=', '')\n",
        "\n",
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "network_pkl = './models/model_%s.pkl' % model_id#(hashlib.md5(model_id.encode()).hexdigest())\n",
        "gdd.download_file_from_google_drive(file_id=model_id,\n",
        "                                    dest_path=network_pkl)\n",
        "\n",
        "!python dataset_tool.py create_from_images ./dataset/hayasaka /content/drive/'My Drive'/twist_moe/hand_tuned_larger_2x/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 719 (delta 0), reused 0 (delta 0), pack-reused 716\u001b[K\n",
            "Receiving objects: 100% (719/719), 16.77 MiB | 39.66 MiB/s, done.\n",
            "Resolving deltas: 100% (463/463), done.\n",
            "/content/stylegan2/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n",
            "Tensorflow version: 1.15.2\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-ec33b791-3b95-7913-c80a-4dfe26657b8a)\n",
            "GPU Identified at: /device:GPU:0\n",
            "Requirement already satisfied: tensorboard in /tensorflow-1.15.2/python3.6 (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (49.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.2.2)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.31.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.9.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.4)\n",
            "Downloading 1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez into ./models/model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl... Done.\n",
            "Loading images from \"/content/drive/My Drive/twist_moe/hand_tuned_larger_2x/\"\n",
            "detected 413 images ...\n",
            "Creating dataset \"./dataset/hayasaka\"\n",
            "Adding the images to tfrecords ...\n",
            "Added 413 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmeWpLdZdhq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b549601-c81c-49b5-97b7-208b97f64689"
      },
      "source": [
        "!python run_training.py --spatial-augmentations=true --lr=0.0005 --num-gpus=1 --data-dir=./dataset --config=config-f --dataset=hayasaka --mirror-augment=true --metric=none --total-kimg=10000 --min-h=4 --min-w=4 --res-log2=7 --result-dir=\"/content/drive/My Drive/twist_moe/results/\" --resume-pkl='./models/model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl'\n",
        "'''\n",
        "#i won't have time to ACTUALLY think about research for at least a week; so I'm just gonna keep this running w/o really knowing what to expect\n",
        "# not very clean, i know, but better than wasting those potential colab hours. \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local submit - run_dir: /content/drive/My Drive/twist_moe/results/00001-stylegan2-hayasaka-1gpu-config-f\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "Dataset shape = [3, 512, 512]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Loading networks from \"./models/model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 16, 512)        -               \n",
            "Truncation/Lerp               -         (?, 16, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
            "G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise13           -         (1, 1, 512, 512)    -               \n",
            "G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n",
            "images_out                    -         (?, 3, 512, 512)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30276583                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 512, 512)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
            "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
            "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "scores_out           -         (?, 1)              -               \n",
            "---                  ---       ---                 ---             \n",
            "Total                28982849                                      \n",
            "\n",
            "Building TensorFlow graph...\n",
            "Initializing logs...\n",
            "Augmenting fakes and reals\n",
            "Augmentation alpha at default setting of 0.1 - change by setting SPATIAL_AUGS_ALPHA environment variable\n",
            "Training for 10000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      lod 0.00  minibatch 4    time 19s          sec/tick 18.6    sec/kimg 1160.24 maintenance 0.0    gpumem 6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLChQRkmgPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!python run_generator.py generate-images --seeds=0-50 --truncation-psi=1.0 --network=/content/drive/'My Drive'/twist_moe/results/00007-stylegan2-hayasaka-1gpu-config-f/network-snapshot-000086.pkl\n",
        "%cp -av /content/stylegan2/results/00000-generate-images /content/drive/'My Drive'/twist_moe/seeds-1.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXzkpzBqnGBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import moviepy.editor\n",
        "from numpy import linalg\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def main():\n",
        "    tflib.init_tf()\n",
        "    _G, _D, Gs = pickle.load(open(\"/content/drive/'My Drive'/twist_moe/results/00006-stylegan2-hayasaka-1gpu-config-f/network-snapshot-000123.pkl\", \"rb\"))\n",
        "\n",
        "    rnd = np.random\n",
        "    latents_a = rnd.randn(1, Gs.input_shape[1])\n",
        "    latents_b = rnd.randn(1, Gs.input_shape[1])\n",
        "    latents_c = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "    def circ_generator(latents_interpolate):\n",
        "        radius = 40.0\n",
        "\n",
        "        latents_axis_x = (latents_a - latents_b).flatten() / linalg.norm(latents_a - latents_b)\n",
        "        latents_axis_y = (latents_a - latents_c).flatten() / linalg.norm(latents_a - latents_c)\n",
        "\n",
        "        latents_x = math.sin(math.pi * 2.0 * latents_interpolate) * radius\n",
        "        latents_y = math.cos(math.pi * 2.0 * latents_interpolate) * radius\n",
        "\n",
        "        latents = latents_a + latents_x * latents_axis_x + latents_y * latents_axis_y\n",
        "        return latents\n",
        "\n",
        "    def mse(x, y):\n",
        "        return (np.square(x - y)).mean()\n",
        "\n",
        "    def generate_from_generator_adaptive(gen_func):\n",
        "        max_step = 1.0\n",
        "        current_pos = 0.0\n",
        "\n",
        "        change_min = 10.0\n",
        "        change_max = 11.0\n",
        "\n",
        "        fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "\n",
        "        current_latent = gen_func(current_pos)\n",
        "        current_image = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n",
        "        array_list = []\n",
        "\n",
        "        video_length = 1.0\n",
        "        while(current_pos < video_length):\n",
        "            array_list.append(current_image)\n",
        "\n",
        "            lower = current_pos\n",
        "            upper = current_pos + max_step\n",
        "            current_pos = (upper + lower) / 2.0\n",
        "\n",
        "            current_latent = gen_func(current_pos)\n",
        "            current_image = images = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n",
        "            current_mse = mse(array_list[-1], current_image)\n",
        "\n",
        "            while current_mse < change_min or current_mse > change_max:\n",
        "                if current_mse < change_min:\n",
        "                    lower = current_pos\n",
        "                    current_pos = (upper + lower) / 2.0\n",
        "\n",
        "                if current_mse > change_max:\n",
        "                    upper = current_pos\n",
        "                    current_pos = (upper + lower) / 2.0\n",
        "\n",
        "\n",
        "                current_latent = gen_func(current_pos)\n",
        "                current_image = images = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n",
        "                current_mse = mse(array_list[-1], current_image)\n",
        "            print(current_pos, current_mse)\n",
        "        return array_list\n",
        "\n",
        "    frames = generate_from_generator_adaptive(circ_generator)\n",
        "    frames = moviepy.editor.ImageSequenceClip(frames, fps=30)\n",
        "\n",
        "    # Generate video.\n",
        "    mp4_file = 'results/circular.mp4'\n",
        "    mp4_codec = 'libx264'\n",
        "    mp4_bitrate = '3M'\n",
        "    mp4_fps = 20\n",
        "\n",
        "    frames.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}