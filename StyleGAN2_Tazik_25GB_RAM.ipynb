{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2_Tazik_25GB_RAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZKTKZ/thdne/blob/master/StyleGAN2_Tazik_25GB_RAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4XmmpwHtwXq",
        "colab_type": "text"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "This document will give you step-by-step instructions on training a GAN to make infinite images of an anime girl of your choice.\n",
        "\n",
        "This would not be possible without the work of many before me -- most notably Gwern, whose pre-trained StyleGAN 2 model is the basis for our transfer learning, and who has also written an in-depth guide on his site; random chinese user on CSDN, whose Colab-specific experiences and code samples were helpful; and nagadomi, for his anime face cropper.\n",
        "\n",
        "My original contribution is a color distance computer to filter undesirable Pixiv data. For characters with sufficient Danbooru images, this is not necessary; but for others, being able to draw on the Pixiv dataset is essential. In my case, Pixiv yielded 1500+ images, of which *hundreds* (25-50%) were not relevant; and the color distance script helped filter it down.\n",
        "\n",
        "This project was my induction into deep learning. I've learnt to parse papers and debug Tensorflow. Of course, this is only the beginning -- to gain a proper, first-principles understanding of the field, I have begun to re-implement important DL papers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDshosOloaLF",
        "colab_type": "text"
      },
      "source": [
        "# Scraping\n",
        "Two sources:\n",
        "\n",
        "1) Danbooru (https://github.com/Bionus/imgbrd-grabber)\n",
        "\n",
        "2) Pixiv (https://github.com/Redcxx/Pikax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptbi4aQgnEiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pikax import Pikax, settings\n",
        "\n",
        "pixiv = Pikax(settings.username, settings.password)\n",
        "\n",
        "results = pixiv.search(keyword='早坂愛')  # search\n",
        "\n",
        "pixiv.download(results)  # download\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVTc7xE0odRT",
        "colab_type": "text"
      },
      "source": [
        "See https://github.com/Redcxx/Pikax for instructions on setting up your `username` & `password`.\n",
        "Next, run Dupeguru (https://github.com/arsenetar/dupeguru/) on your downloaded images. \n",
        "\n",
        "Danbooru consists primarily of high tier images for Pixiv, and this step prevents duplication.\n",
        "Now that we have our data, on to processing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRXDhX-Tv0Ru",
        "colab_type": "text"
      },
      "source": [
        "# Cropping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REoeE_gyn3i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/nagadomi/lbpcascade_animeface/blob/master/examples/detect.py\n",
        "\n",
        "import imutils\n",
        "import cv2\n",
        "import sys\n",
        "import os.path\n",
        "\n",
        "def detect(abs_filename, cascade_file = \"../lbpcascade_animeface.xml\"):#, mode=\"display\"):\n",
        "    if not os.path.isfile(cascade_file):\n",
        "        raise RuntimeError(\"%s: not found\" % cascade_file)\n",
        "\n",
        "    cascade = cv2.CascadeClassifier(cascade_file)\n",
        "    image = cv2.imread(abs_filename, cv2.IMREAD_COLOR)\n",
        "    #height, width, channels = image.shape\n",
        "    #image = image[0: int(h/2), 0: w]\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.equalizeHist(gray)\n",
        "    \n",
        "    faces = cascade.detectMultiScale(gray,\n",
        "                                     # detector options\n",
        "                                     scaleFactor = 1.05,\n",
        "                                     minNeighbors = 5,\n",
        "                                     minSize = (250, 250)\n",
        "                                     #,maxSize = (int(0.4*w), int(0.4*h))\n",
        "                                     )\n",
        "    tag = 0\n",
        "    filename = os.path.basename(abs_filename)\n",
        "    for (x, y, w, h) in faces:\n",
        "\n",
        "        #cv2.rectangle(image, (int(x*0.85), int(y*0.1)), (x + int(w*1.5), y + h), (255, 0, 0), 50)\n",
        "        cropped = image[int(y*0.2): y + int(h*0.825), int(x*0.95): x + int(w*1.225)]\n",
        "        #cv2.imshow(\"AnimeFaceDetect\", imutils.resize(cropped, width=1080, height=1366))        cv2.waitKey(0)\n",
        "        cv2.imwrite(str(filename[0:-4] + '_' + str(tag) + filename[-4:]), cropped)\n",
        "        tag += 1\n",
        "\n",
        "if len(sys.argv) != 2:\n",
        "    sys.stderr.write(\"usage: detect.py <abs_filename>\\n\")\n",
        "    sys.exit(-1)\n",
        "detect(sys.argv[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilHhY9FZoYJc",
        "colab_type": "text"
      },
      "source": [
        "You may want to modify the parameters. I crop the images rather selectively, to minimize background noise. The `scaleFactor` determines how many scales of the image the classification is run on. A lower value means more results, but also more false positives. The other two parameters are self-descriptive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3hT1PWODvcv",
        "colab_type": "text"
      },
      "source": [
        "## Upscaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M76qFwNeo4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /usr/local/cuda/version.txt\n",
        "!wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\n",
        "!sudo dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\n",
        "!apt-get install libvulkan-dev\n",
        "!apt-get update\n",
        "\n",
        "!%cd /content/\n",
        "!git clone https://github.com/nihui/waifu2x-ncnn-vulkan.git\n",
        "!cd waifu2x-ncnn-vulkan/\n",
        "!git submodule update --init --recursive\n",
        "!wget https://github.com/nihui/waifu2x-ncnn-vulkan/releases/download/20200606/waifu2x-ncnn-vulkan-20200606-linux.zip\n",
        "!unzip waifu2x-ncnn-vulkan-20200606-linux.zip\n",
        "%cd waifu2x-ncnn-vulkan-20200606-linux\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONHKknp7D1XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload all files first ->\n",
        "%mkdir 2x\n",
        "!for img in *.??g; do ./waifu2x-ncnn-vulkan -i $img -o 2x/${img%.*}_2x.png; done\n",
        "\n",
        "# copying in gdrive\n",
        "#!gsutil -m cp -r hand_tuned_larger/ '/content/drive/My Drive/twist_moe/hand_tuned_larger_2x/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOvrhlKDpnPO",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning\n",
        "\n",
        "After obtaining the cropped images, I run the shell scripts in this Git repository, courtesy of Gwern. The one change I made is to preserve the JPGs at 100% quality, as I have a small dataset.\n",
        "\n",
        "After changing the directory parameter, run them in the following order:\n",
        "\n",
        "delete -> convert -> resize -> final\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCM1wNepqHf5",
        "colab_type": "text"
      },
      "source": [
        "I downloaded *all* images of Hayasaka from Pixiv. Unlike Danbooru, Pixiv does not have proper image tags. So, to separate images of Hayasaka from images we don't want (black & white, other characters), I devised the following script, which calculates distance of the dominant color in thte image from RGB yellow (255, 255, 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAx-JARVqiWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os \n",
        "from time import sleep\n",
        "from colorthief import ColorThief\n",
        "\n",
        "for root, dirs, files in os.walk('/home/tazik/Nextcloud/code/lbpcascade_animeface/examples/datasets/hand_tuned_larger_2x/'):\n",
        "    #print(root, dirs, files)\n",
        "    for name in files:\n",
        "        print(name)\n",
        "        color_thief = ColorThief(os.path.join(root, name))\n",
        "        palette = color_thief.get_palette(color_count=2, quality=1)\n",
        "        rgb = palette[0]\n",
        "        delta_E = pow(rgb[0]-255, 2) + pow(rgb[1]-255,2) + pow(rgb[2], 2)\n",
        "        print(delta_E)\n",
        "        new_name = os.path.join(root, str(delta_E) + \".png\")\n",
        "        os.rename(os.path.join(root, name), new_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqTxN576rBzt",
        "colab_type": "text"
      },
      "source": [
        "The script renames images according to \"yellowness\", making it easy to eliminate non-matching images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk6ezENIrQvO",
        "colab_type": "text"
      },
      "source": [
        "Now, it's time to use Colab. We use the pre-trained anime face StyleGan2 model to rank the our pre-processed images. This helps with filtering, as higher ranked images tend to be lower quality. \n",
        "\n",
        "This trick is also courtesy of Gwern."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fimqSTw_CSNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CSDN blog\n",
        "#https://translate.googleusercontent.com/translate_c?depth=1&pto=aue&rurl=translate.google.com&sl=auto&sp=nmt4&tl=en&u=https://blog.csdn.net/DLW__/article/details/104222546&usg=ALkJrhjWEtjIz8Yklx8uSjuFQuv7O9bPnA\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "#import config\n",
        "import sys\n",
        "\n",
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "import pretrained_networks\n",
        "\n",
        "# StyleGAN2 Danbooru Portrait\n",
        "url = 'https://drive.google.com/open?id=1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez'\n",
        "#'https://drive.google.com/open?id=1BHeqOZ58WZ-vACR2MJkh1ZVbJK2B-Kle'\n",
        "model_id = url.replace('https://drive.google.com/open?id=', '')\n",
        "\n",
        "network_pkl = '/content/models/model_%s.pkl' % model_id#(hashlib.md5(model_id.encode()).hexdigest())\n",
        "gdd.download_file_from_google_drive(file_id=model_id,\n",
        "                                    dest_path=network_pkl)\n",
        "\n",
        "\n",
        "# If downloads fails, due to 'Google Drive download quota exceeded' you can try downloading manually from your own Google Drive account\n",
        "# network_pkl = \"/content/drive/My Drive/GAN/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "\n",
        "def main(origin_dir):\n",
        "    image_names = [files for root, dirs, files in os.walk(origin_dir)][0]\n",
        "    print('find %s files in %s' % (len(image_names), origin_dir))\n",
        "\n",
        "    tflib.init_tf()\n",
        "    print('Loading networks from \"%s\"...' % network_pkl)\n",
        "    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "\n",
        "    for index, image_name in enumerate(image_names):\n",
        "        image_path = os.path.join(origin_dir, image_name)\n",
        "        img = np.asarray(PIL.Image.open(image_path))\n",
        "        img = img.reshape(1, 3, 512, 512)\n",
        "        score = _D.run(img, None)\n",
        "        os.rename(image_path, os.path.join(origin_dir, '%s_%s.png' % (score[0][0], index)))\n",
        "        print(image_name, score[0][0])\n",
        "\n",
        "    print('Done!')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main('/content/drive/My Drive/twist_moe/hand_tuned/')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRbH4y4DtLM7",
        "colab_type": "text"
      },
      "source": [
        "Finally, I go through the images to look for potential outliers. I spent a bit of time on this step, as there were many low quality images of Hayasaka that I did not want the model to be learning from. This step could potentially be made redundant if one appropriately filters Pixiv images by art type. But the art categories are not immediately apparent to non-Pixiv users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR8n0yeImPCx",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "## Colab Hacks\n",
        "\n",
        "```\n",
        "i = []\n",
        "while True:\n",
        "  i.append(i)\n",
        "```\n",
        "\n",
        "The above is used to induce Google to offer you more RAM. Do note that this does not work on newly initialized notebooks, after a patch by Google; instead, you have to use an older notebook as your base (e.g. make a copy of this NB).\n",
        "\n",
        "Keep Colab from disconnecting after 1.5hrs.\n",
        "\n",
        "```\n",
        "\n",
        "function KeepClicking(){\n",
        "   console.log(\"Clicking\");\n",
        "   document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(KeepClicking,60000)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE5GqZHcHHBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "ea6f008d-7aab-4061-bbd9-815e64e0b836"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/ZKTKZ/stylegan2.git\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))\n",
        "\n",
        "!pip install tensorboard\n",
        "\n",
        "url = 'https://drive.google.com/open?id=1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez'\n",
        "#'https://drive.google.com/open?id=1BHeqOZ58WZ-vACR2MJkh1ZVbJK2B-Kle'\n",
        "model_id = url.replace('https://drive.google.com/open?id=', '')\n",
        "\n",
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "network_pkl = './models/model_%s.pkl' % model_id#(hashlib.md5(model_id.encode()).hexdigest())\n",
        "gdd.download_file_from_google_drive(file_id=model_id,\n",
        "                                    dest_path=network_pkl)\n",
        "\n",
        "#!python dataset_tool.py create_from_images ./dataset/hayasaka /content/drive/'My Drive'/twist_moe/hand_tuned_larger_2x/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 719 (delta 0), reused 0 (delta 0), pack-reused 716\u001b[K\n",
            "Receiving objects: 100% (719/719), 16.77 MiB | 8.28 MiB/s, done.\n",
            "Resolving deltas: 100% (462/462), done.\n",
            "/content/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n",
            "Tensorflow version: 1.15.2\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-5bfa2c39-f4bd-ab01-188a-cce1134eb9ed)\n",
            "GPU Identified at: /device:GPU:0\n",
            "Requirement already satisfied: tensorboard in /tensorflow-1.15.2/python3.6 (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.34.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (49.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.31.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.4)\n",
            "Downloading 1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez into ./models/model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmeWpLdZdhq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b549601-c81c-49b5-97b7-208b97f64689"
      },
      "source": [
        "!python run_training.py --spatial-augmentations=true --lr=0.0005 --num-gpus=1 --data-dir=./dataset --config=config-f --dataset=hayasaka --mirror-augment=true --metric=none --total-kimg=10000 --min-h=4 --min-w=4 --res-log2=7 --result-dir=\"/content/drive/My Drive/twist_moe/results/\" --resume-pkl='./models/model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl'\n",
        "'''\n",
        "#i won't have time to ACTUALLY think about research for at least a week; so I'm just gonna keep this running w/o really knowing what to expect\n",
        "# not very clean, i know, but better than wasting those potential colab hours. \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local submit - run_dir: /content/drive/My Drive/twist_moe/results/00001-stylegan2-hayasaka-1gpu-config-f\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "Dataset shape = [3, 512, 512]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Loading networks from \"./models/model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 16, 512)        -               \n",
            "Truncation/Lerp               -         (?, 16, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
            "G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise13           -         (1, 1, 512, 512)    -               \n",
            "G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n",
            "images_out                    -         (?, 3, 512, 512)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30276583                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 512, 512)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
            "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
            "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "scores_out           -         (?, 1)              -               \n",
            "---                  ---       ---                 ---             \n",
            "Total                28982849                                      \n",
            "\n",
            "Building TensorFlow graph...\n",
            "Initializing logs...\n",
            "Augmenting fakes and reals\n",
            "Augmentation alpha at default setting of 0.1 - change by setting SPATIAL_AUGS_ALPHA environment variable\n",
            "Training for 10000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      lod 0.00  minibatch 4    time 19s          sec/tick 18.6    sec/kimg 1160.24 maintenance 0.0    gpumem 6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2Ln57WdwKcu",
        "colab_type": "text"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLChQRkmgPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!python run_generator.py generate-images --seeds=0-50 --truncation-psi=1.0 --network=/content/drive/'My Drive'/twist_moe/results/00007-stylegan2-hayasaka-1gpu-config-f/network-snapshot-000086.pkl\n",
        "%cp -av /content/stylegan2/results/00000-generate-images /content/drive/'My Drive'/twist_moe/seeds-1.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXzkpzBqnGBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4a5ebed-f969-4fbf-9851-965efb8cfc33"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import scipy\n",
        "import math\n",
        "import moviepy.editor\n",
        "from numpy import linalg\n",
        "\n",
        "\n",
        "def main():\n",
        "    tflib.init_tf()\n",
        "    _G, _D, Gs = pickle.load(open(\"/content/drive/My Drive/twist_moe/results/00001-stylegan2-hayasaka-1gpu-config-f/network-snapshot-000108.pkl\", \"rb\"))\n",
        "\n",
        "    rnd = np.random\n",
        "    latents_a = rnd.randn(1, Gs.input_shape[1])\n",
        "    latents_b = rnd.randn(1, Gs.input_shape[1])\n",
        "    latents_c = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "    def circ_generator(latents_interpolate):\n",
        "        radius = 40.0\n",
        "\n",
        "        latents_axis_x = (latents_a - latents_b).flatten() / linalg.norm(latents_a - latents_b)\n",
        "        latents_axis_y = (latents_a - latents_c).flatten() / linalg.norm(latents_a - latents_c)\n",
        "\n",
        "        latents_x = math.sin(math.pi * 2.0 * latents_interpolate) * radius\n",
        "        latents_y = math.cos(math.pi * 2.0 * latents_interpolate) * radius\n",
        "\n",
        "        latents = latents_a + latents_x * latents_axis_x + latents_y * latents_axis_y\n",
        "        return latents\n",
        "\n",
        "    def mse(x, y):\n",
        "        return (np.square(x - y)).mean()\n",
        "\n",
        "    def generate_from_generator_adaptive(gen_func):\n",
        "        max_step = 1.0\n",
        "        current_pos = 0.0\n",
        "\n",
        "        change_min = 10.0\n",
        "        change_max = 11.0\n",
        "\n",
        "        fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "\n",
        "        current_latent = gen_func(current_pos)\n",
        "        current_image = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n",
        "        array_list = []\n",
        "\n",
        "        video_length = 1.0\n",
        "        while(current_pos < video_length):\n",
        "            array_list.append(current_image)\n",
        "\n",
        "            lower = current_pos\n",
        "            upper = current_pos + max_step\n",
        "            current_pos = (upper + lower) / 2.0\n",
        "\n",
        "            current_latent = gen_func(current_pos)\n",
        "            current_image = images = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n",
        "            current_mse = mse(array_list[-1], current_image)\n",
        "\n",
        "            while current_mse < change_min or current_mse > change_max:\n",
        "                if current_mse < change_min:\n",
        "                    lower = current_pos\n",
        "                    current_pos = (upper + lower) / 2.0\n",
        "\n",
        "                if current_mse > change_max:\n",
        "                    upper = current_pos\n",
        "                    current_pos = (upper + lower) / 2.0\n",
        "\n",
        "\n",
        "                current_latent = gen_func(current_pos)\n",
        "                current_image = images = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n",
        "                current_mse = mse(array_list[-1], current_image)\n",
        "            print(current_pos, current_mse)\n",
        "        return array_list\n",
        "\n",
        "    frames = generate_from_generator_adaptive(circ_generator)\n",
        "    frames = moviepy.editor.ImageSequenceClip(frames, fps=30)\n",
        "\n",
        "    # Generate video.\n",
        "    mp4_file = 'circular.mp4'\n",
        "    mp4_codec = 'libx264'\n",
        "    mp4_bitrate = '3M'\n",
        "    mp4_fps = 20\n",
        "\n",
        "    frames.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0048828125 10.820354461669922\n",
            "0.009765625 10.70547866821289\n",
            "0.01416015625 10.360978444417318\n",
            "0.01806640625 10.894938151041666\n",
            "0.021484375 10.118396759033203\n",
            "0.025390625 10.849322001139322\n",
            "0.02978515625 10.78615951538086\n",
            "0.03466796875 10.167156219482422\n",
            "0.03955078125 10.489190419514975\n",
            "0.0439453125 10.901374816894531\n",
            "0.0478515625 10.394774119059244\n",
            "0.052001953125 10.44314702351888\n",
            "0.055908203125 10.766268412272135\n",
            "0.060791015625 10.845558166503906\n",
            "0.065185546875 10.215494791666666\n",
            "0.069580078125 10.807979583740234\n",
            "0.073974609375 10.199207305908203\n",
            "0.079833984375 10.297117869059244\n",
            "0.086181640625 10.543169657389322\n",
            "0.093505859375 10.48687998453776\n",
            "0.099365234375 10.417231241861979\n",
            "0.105224609375 10.96579106648763\n",
            "0.110107421875 10.64813486735026\n",
            "0.115478515625 10.44927978515625\n",
            "0.122314453125 10.216688791910807\n",
            "0.128173828125 10.492900848388672\n",
            "0.134521484375 10.73840077718099\n",
            "0.140380859375 10.508065541585287\n",
            "0.146240234375 10.923501332600912\n",
            "0.152099609375 10.371228535970053\n",
            "0.157470703125 10.738150278727213\n",
            "0.163330078125 10.809993743896484\n",
            "0.167724609375 10.990403493245443\n",
            "0.171142578125 10.688271840413412\n",
            "0.174072265625 10.191022237141928\n",
            "0.177001953125 10.814305623372396\n",
            "0.1796875 10.143931070963541\n",
            "0.182373046875 10.799559275309244\n",
            "0.18505859375 10.080081939697266\n",
            "0.1875 10.607835133870443\n",
            "0.189697265625 10.637205759684244\n",
            "0.191650390625 10.292919158935547\n",
            "0.19384765625 10.576576232910156\n",
            "0.196044921875 10.585338592529297\n",
            "0.19873046875 10.931233723958334\n",
            "0.201416015625 10.494070688883463\n",
            "0.2041015625 10.375871022542318\n",
            "0.20703125 10.756292978922525\n",
            "0.21044921875 10.389341990152994\n",
            "0.21337890625 10.040245056152344\n",
            "0.21630859375 10.463511149088541\n",
            "0.22021484375 10.345956166585287\n",
            "0.22509765625 10.265130360921225\n",
            "0.22998046875 10.20495351155599\n",
            "0.23486328125 10.081404368082682\n",
            "0.240234375 10.754571278889975\n",
            "0.24609375 10.663256327311197\n",
            "0.2509765625 10.001983642578125\n",
            "0.255859375 10.501425425211588\n",
            "0.2607421875 10.119761149088541\n",
            "0.265625 10.564861297607422\n",
            "0.27001953125 10.253365834554037\n",
            "0.27490234375 10.928091684977213\n",
            "0.27978515625 10.47586186726888\n",
            "0.2841796875 10.447372436523438\n",
            "0.28857421875 10.254664103190104\n",
            "0.29248046875 10.350382486979166\n",
            "0.296630859375 10.575701395670572\n",
            "0.299560546875 10.887990315755209\n",
            "0.3017578125 10.01144790649414\n",
            "0.30419921875 10.75625228881836\n",
            "0.30712890625 10.587409973144531\n",
            "0.3095703125 10.791015625\n",
            "0.31201171875 10.882732391357422\n",
            "0.314697265625 10.579124450683594\n",
            "0.31787109375 10.363016764322916\n",
            "0.320556640625 10.903719584147135\n",
            "0.32275390625 10.554570515950521\n",
            "0.32470703125 10.599052429199219\n",
            "0.326416015625 10.874368031819662\n",
            "0.327880859375 10.61346689860026\n",
            "0.3291015625 10.216949462890625\n",
            "0.3302001953125 10.251466115315756\n",
            "0.3311767578125 10.181407928466797\n",
            "0.3321533203125 10.373577117919922\n",
            "0.3331298828125 10.551434834798178\n",
            "0.333984375 10.495314280192057\n",
            "0.3348388671875 10.228505452473959\n",
            "0.335693359375 10.127794901529947\n",
            "0.3365478515625 10.589916229248047\n",
            "0.3372802734375 10.446851094563803\n",
            "0.3380126953125 10.791699727376303\n",
            "0.3387451171875 10.490665435791016\n",
            "0.339599609375 10.577521006266275\n",
            "0.3404541015625 10.7344118754069\n",
            "0.34130859375 10.480246225992838\n",
            "0.3421630859375 10.46502685546875\n",
            "0.343017578125 10.758336385091146\n",
            "0.3438720703125 10.685713450113932\n",
            "0.3447265625 10.45794677734375\n",
            "0.345703125 10.716509501139322\n",
            "0.3466796875 10.51092274983724\n",
            "0.3477783203125 10.33688227335612\n",
            "0.3489990234375 10.236244201660156\n",
            "0.3504638671875 10.457658131917318\n",
            "0.3519287109375 10.363138834635416\n",
            "0.3531494140625 10.395153045654297\n",
            "0.354248046875 10.607986450195312\n",
            "0.3551025390625 10.211039225260416\n",
            "0.35595703125 10.2414182027181\n",
            "0.3568115234375 10.545665740966797\n",
            "0.3575439453125 10.02237319946289\n",
            "0.3582763671875 10.185775756835938\n",
            "0.3590087890625 10.295908610026041\n",
            "0.3597412109375 10.323487599690756\n",
            "0.36053466796875 10.451388041178385\n",
            "0.36138916015625 10.916641235351562\n",
            "0.36224365234375 10.675565083821615\n",
            "0.36309814453125 10.73800277709961\n",
            "0.36395263671875 10.678553263346354\n",
            "0.36492919921875 10.721331278483072\n",
            "0.36590576171875 10.442293802897135\n",
            "0.36700439453125 10.51394271850586\n",
            "0.36810302734375 10.854228973388672\n",
            "0.36932373046875 10.667621612548828\n",
            "0.37054443359375 10.679551442464193\n",
            "0.37176513671875 10.336522420247396\n",
            "0.37310791015625 10.802464803059896\n",
            "0.37432861328125 10.32834243774414\n",
            "0.37542724609375 10.141595204671225\n",
            "0.37664794921875 10.061481475830078\n",
            "0.37786865234375 10.808836619059244\n",
            "0.37896728515625 10.93060048421224\n",
            "0.37994384765625 10.178882598876953\n",
            "0.38092041015625 10.596913655598959\n",
            "0.38177490234375 10.986428578694662\n",
            "0.382568359375 10.465833028157553\n",
            "0.383544921875 10.80227533976237\n",
            "0.384521484375 10.317587534586588\n",
            "0.3853759765625 10.254934946695963\n",
            "0.3861083984375 10.062371571858725\n",
            "0.386962890625 10.521448771158854\n",
            "0.387939453125 10.785697937011719\n",
            "0.38916015625 10.825571695963541\n",
            "0.3905029296875 10.11517333984375\n",
            "0.3916015625 10.886778513590494\n",
            "0.3927001953125 10.580093383789062\n",
            "0.3936767578125 10.659339904785156\n",
            "0.39453125 10.228036244710287\n",
            "0.3953857421875 10.05447006225586\n",
            "0.39617919921875 10.26748275756836\n",
            "0.3968505859375 10.568683624267578\n",
            "0.3974609375 10.018230438232422\n",
            "0.3980712890625 10.041726430257162\n",
            "0.398681640625 10.580766042073568\n",
            "0.39923095703125 10.393716176350912\n",
            "0.3997802734375 10.474561055501303\n",
            "0.40032958984375 10.72735341389974\n",
            "0.40081787109375 10.081259409586588\n",
            "0.40130615234375 10.181078592936197\n",
            "0.40179443359375 10.383799235026041\n",
            "0.402252197265625 10.692288716634115\n",
            "0.402679443359375 10.365545908610025\n",
            "0.40313720703125 10.354825337727865\n",
            "0.403564453125 10.021645863850912\n",
            "0.404022216796875 10.65140151977539\n",
            "0.40447998046875 10.494102478027344\n",
            "0.40496826171875 10.693958282470703\n",
            "0.405426025390625 10.427595774332682\n",
            "0.405914306640625 10.85259755452474\n",
            "0.406402587890625 10.643102010091146\n",
            "0.406890869140625 10.812283833821615\n",
            "0.407318115234375 10.091209411621094\n",
            "0.40777587890625 10.511002858479818\n",
            "0.40826416015625 10.94064458211263\n",
            "0.40875244140625 10.257282257080078\n",
            "0.4093017578125 10.924335479736328\n",
            "0.409820556640625 10.545038859049479\n",
            "0.410308837890625 10.460065205891928\n",
            "0.410797119140625 10.009899139404297\n",
            "0.411346435546875 10.803474426269531\n",
            "0.411895751953125 10.654022216796875\n",
            "0.412445068359375 10.537863413492838\n",
            "0.412994384765625 10.293992360432943\n",
            "0.413543701171875 10.31829833984375\n",
            "0.414093017578125 10.567148844401041\n",
            "0.414581298828125 10.426382700602213\n",
            "0.415130615234375 10.59115982055664\n",
            "0.415679931640625 10.879474639892578\n",
            "0.416229248046875 10.718900044759115\n",
            "0.416778564453125 10.295909881591797\n",
            "0.417266845703125 10.402369181315104\n",
            "0.417724609375 10.447461446126303\n",
            "0.418212890625 10.484797159830729\n",
            "0.41876220703125 10.559652964274088\n",
            "0.41937255859375 10.347600301106771\n",
            "0.41998291015625 10.548951466878256\n",
            "0.42059326171875 10.978098551432291\n",
            "0.42120361328125 10.536680857340494\n",
            "0.421875 10.41677983601888\n",
            "0.42254638671875 10.419746398925781\n",
            "0.42315673828125 10.127727508544922\n",
            "0.423828125 10.373897552490234\n",
            "0.42449951171875 10.761002858479818\n",
            "0.4251708984375 10.435176849365234\n",
            "0.42584228515625 10.314566294352213\n",
            "0.426513671875 10.727897644042969\n",
            "0.4271240234375 10.769883473714193\n",
            "0.4278564453125 10.96164321899414\n",
            "0.4285888671875 10.490753173828125\n",
            "0.4293212890625 10.674535115559896\n",
            "0.4300537109375 10.535428365071615\n",
            "0.4307861328125 10.347885131835938\n",
            "0.4315185546875 10.181682586669922\n",
            "0.4322509765625 10.861255645751953\n",
            "0.43292236328125 10.371359507242838\n",
            "0.43359375 10.504158020019531\n",
            "0.43426513671875 10.66141128540039\n",
            "0.43499755859375 10.541241963704428\n",
            "0.435791015625 10.651658376057943\n",
            "0.4365234375 10.2748654683431\n",
            "0.437255859375 10.519753774007162\n",
            "0.4378662109375 10.00149917602539\n",
            "0.43865966796875 10.44518788655599\n",
            "0.43951416015625 10.690933227539062\n",
            "0.44036865234375 10.180501302083334\n",
            "0.44122314453125 10.52010981241862\n",
            "0.4420166015625 10.598821004231771\n",
            "0.4427490234375 10.00732676188151\n",
            "0.4434814453125 10.041200002034506\n",
            "0.4442138671875 10.344537099202475\n",
            "0.4449462890625 10.283172607421875\n",
            "0.44580078125 10.8426144917806\n",
            "0.446533203125 10.470413208007812\n",
            "0.447265625 10.435223897298178\n",
            "0.447998046875 10.495004018147787\n",
            "0.44873046875 10.07772445678711\n",
            "0.449462890625 10.88326644897461\n",
            "0.4500732421875 10.281883239746094\n",
            "0.45068359375 10.813395182291666\n",
            "0.45123291015625 10.512545267740885\n",
            "0.4517822265625 10.424400329589844\n",
            "0.45233154296875 10.746236165364584\n",
            "0.45281982421875 10.573657989501953\n",
            "0.45330810546875 10.66571044921875\n",
            "0.4537353515625 10.129582722981771\n",
            "0.45416259765625 10.251973470052084\n",
            "0.45458984375 10.329808553059896\n",
            "0.455078125 10.819988250732422\n",
            "0.45550537109375 10.180613199869791\n",
            "0.4559326171875 10.538168589274088\n",
            "0.45635986328125 10.209515889485678\n",
            "0.456756591796875 10.680861155192057\n",
            "0.457122802734375 10.722478230794271\n",
            "0.45751953125 10.557927449544271\n",
            "0.45794677734375 10.477586110432943\n",
            "0.4583740234375 10.637095133463541\n",
            "0.458740234375 10.820648193359375\n",
            "0.459136962890625 10.5691286722819\n",
            "0.459625244140625 10.609549204508463\n",
            "0.460113525390625 10.208218892415365\n",
            "0.460723876953125 10.1407101949056\n",
            "0.461334228515625 10.209678649902344\n",
            "0.461883544921875 10.150215148925781\n",
            "0.462432861328125 10.822154998779297\n",
            "0.462982177734375 10.907394409179688\n",
            "0.463531494140625 10.328418731689453\n",
            "0.464141845703125 10.367691040039062\n",
            "0.464874267578125 10.970205942789713\n",
            "0.465484619140625 10.540294647216797\n",
            "0.466033935546875 10.83340326944987\n",
            "0.466583251953125 10.641571044921875\n",
            "0.467132568359375 10.486679077148438\n",
            "0.467681884765625 10.701761881510416\n",
            "0.468231201171875 10.319867451985678\n",
            "0.468902587890625 10.432551066080729\n",
            "0.469635009765625 10.9545529683431\n",
            "0.470489501953125 10.73416010538737\n",
            "0.471282958984375 10.526092529296875\n",
            "0.472137451171875 10.730692545572916\n",
            "0.472991943359375 10.470909118652344\n",
            "0.473846435546875 10.541491190592447\n",
            "0.474639892578125 10.56179936726888\n",
            "0.475372314453125 10.806944529215494\n",
            "0.476104736328125 10.587982177734375\n",
            "0.476837158203125 10.461554209391275\n",
            "0.477569580078125 10.53109868367513\n",
            "0.478302001953125 10.703263600667318\n",
            "0.479034423828125 10.77518081665039\n",
            "0.479766845703125 10.769153594970703\n",
            "0.480621337890625 10.106758117675781\n",
            "0.481597900390625 10.814762115478516\n",
            "0.482574462890625 10.02615229288737\n",
            "0.483551025390625 10.468238830566406\n",
            "0.484527587890625 10.760279337565104\n",
            "0.485626220703125 10.707650502522787\n",
            "0.486480712890625 10.249018351236979\n",
            "0.487213134765625 10.597527821858725\n",
            "0.487945556640625 10.679288228352865\n",
            "0.488616943359375 10.77743911743164\n",
            "0.489227294921875 10.61013666788737\n",
            "0.489837646484375 10.67422358194987\n",
            "0.490447998046875 10.066680908203125\n",
            "0.491180419921875 10.942554473876953\n",
            "0.491851806640625 10.687864939371744\n",
            "0.492584228515625 10.857115427652994\n",
            "0.493316650390625 10.458507537841797\n",
            "0.494049072265625 10.062559763590494\n",
            "0.494842529296875 10.431601206461588\n",
            "0.495574951171875 10.121869405110678\n",
            "0.496429443359375 10.521380106608072\n",
            "0.497161865234375 10.049302419026693\n",
            "0.497833251953125 10.348690032958984\n",
            "0.498565673828125 10.977425893147787\n",
            "0.499298095703125 10.746262868245443\n",
            "0.499969482421875 10.410592397054037\n",
            "0.500640869140625 10.406291961669922\n",
            "0.501373291015625 10.271305084228516\n",
            "0.502105712890625 10.004573822021484\n",
            "0.502838134765625 10.8651123046875\n",
            "0.503570556640625 10.959768931070963\n",
            "0.504241943359375 10.386550903320312\n",
            "0.504974365234375 10.713775634765625\n",
            "0.505706787109375 10.42197291056315\n",
            "0.506500244140625 10.450143178304037\n",
            "0.507232666015625 10.121163686116537\n",
            "0.507965087890625 10.187451680501303\n",
            "0.508941650390625 10.939908345540365\n",
            "0.509796142578125 10.24880345662435\n",
            "0.510772705078125 10.802598317464193\n",
            "0.511749267578125 10.578207651774088\n",
            "0.512725830078125 10.140703837076822\n",
            "0.513702392578125 10.248263041178385\n",
            "0.514678955078125 10.521686553955078\n",
            "0.515655517578125 10.061589558919271\n",
            "0.516632080078125 10.570657094319662\n",
            "0.517608642578125 10.8590087890625\n",
            "0.518463134765625 10.442768096923828\n",
            "0.519317626953125 10.366170247395834\n",
            "0.520172119140625 10.52917226155599\n",
            "0.521026611328125 10.84668223063151\n",
            "0.521820068359375 10.482686360677084\n",
            "0.522674560546875 10.729441324869791\n",
            "0.523529052734375 10.715750376383463\n",
            "0.524383544921875 10.090579986572266\n",
            "0.525238037109375 10.1317990620931\n",
            "0.526092529296875 10.424694061279297\n",
            "0.527008056640625 10.467923482259115\n",
            "0.527862548828125 10.235342661539713\n",
            "0.528717041015625 10.862840016682943\n",
            "0.529449462890625 10.248981475830078\n",
            "0.530181884765625 10.047952016194662\n",
            "0.531036376953125 10.869955698649088\n",
            "0.531829833984375 10.370197296142578\n",
            "0.532623291015625 10.424087524414062\n",
            "0.533477783203125 10.878289540608725\n",
            "0.534210205078125 10.113525390625\n",
            "0.535064697265625 10.919156392415365\n",
            "0.535919189453125 10.744544982910156\n",
            "0.536773681640625 10.407459259033203\n",
            "0.537628173828125 10.048662821451822\n",
            "0.538604736328125 10.980255126953125\n",
            "0.539459228515625 10.145174662272135\n",
            "0.540313720703125 10.957618713378906\n",
            "0.541168212890625 10.780634562174479\n",
            "0.542022705078125 10.977771759033203\n",
            "0.542816162109375 10.346028645833334\n",
            "0.543548583984375 10.441293080647787\n",
            "0.544281005859375 10.514291127522787\n",
            "0.545013427734375 10.330132802327475\n",
            "0.545806884765625 10.534191131591797\n",
            "0.546661376953125 10.417897542317709\n",
            "0.547576904296875 10.555730183919271\n",
            "0.548431396484375 10.59844970703125\n",
            "0.549285888671875 10.596782684326172\n",
            "0.550140380859375 10.649244944254557\n",
            "0.550933837890625 10.454900105794271\n",
            "0.551666259765625 10.37738037109375\n",
            "0.552398681640625 10.9058837890625\n",
            "0.553070068359375 10.507643381754557\n",
            "0.553741455078125 10.591405232747396\n",
            "0.554412841796875 10.466965993245443\n",
            "0.555145263671875 10.890398661295572\n",
            "0.555816650390625 10.48870849609375\n",
            "0.556488037109375 10.654090881347656\n",
            "0.557159423828125 10.620713551839193\n",
            "0.557830810546875 10.50680669148763\n",
            "0.558502197265625 10.599979400634766\n",
            "0.559112548828125 10.022293090820312\n",
            "0.559722900390625 10.1118532816569\n",
            "0.560333251953125 10.064053853352865\n",
            "0.560943603515625 10.365835825602213\n",
            "0.561553955078125 10.237688700358072\n",
            "0.562164306640625 10.396867116292318\n",
            "0.562774658203125 10.164016723632812\n",
            "0.563446044921875 10.645172119140625\n",
            "0.564056396484375 10.053915659586588\n",
            "0.564727783203125 10.638164520263672\n",
            "0.565399169921875 10.595972696940104\n",
            "0.566131591796875 10.710948944091797\n",
            "0.566802978515625 10.486137390136719\n",
            "0.567474365234375 10.642908732096354\n",
            "0.568084716796875 10.02675755818685\n",
            "0.568817138671875 10.688021341959635\n",
            "0.569549560546875 10.601369222005209\n",
            "0.570281982421875 10.275630950927734\n",
            "0.571136474609375 10.484193166097006\n",
            "0.572113037109375 10.876199086507162\n",
            "0.573089599609375 10.604408264160156\n",
            "0.574066162109375 10.352121988932291\n",
            "0.575042724609375 10.269828796386719\n",
            "0.576141357421875 10.578736623128256\n",
            "0.577117919921875 10.370447794596354\n",
            "0.578094482421875 10.823023478190104\n",
            "0.579071044921875 10.48364003499349\n",
            "0.580047607421875 10.212502797444662\n",
            "0.581024169921875 10.627207438151041\n",
            "0.582000732421875 10.34787114461263\n",
            "0.582977294921875 10.313644409179688\n",
            "0.583953857421875 10.38500722249349\n",
            "0.584930419921875 10.324577331542969\n",
            "0.585906982421875 10.555159250895182\n",
            "0.586883544921875 10.968266805013021\n",
            "0.587799072265625 10.52432378133138\n",
            "0.588653564453125 10.452320098876953\n",
            "0.589630126953125 10.701939900716146\n",
            "0.590606689453125 10.650918324788412\n",
            "0.591583251953125 10.48562240600586\n",
            "0.592559814453125 10.647172292073568\n",
            "0.593536376953125 10.903013865152994\n",
            "0.594635009765625 10.700002034505209\n",
            "0.595855712890625 10.892630259195963\n",
            "0.597076416015625 10.54324213663737\n",
            "0.598297119140625 10.186536153157553\n",
            "0.599517822265625 10.576760609944662\n",
            "0.600616455078125 10.077500661214193\n",
            "0.601837158203125 10.873311360677084\n",
            "0.603057861328125 10.462151845296225\n",
            "0.604400634765625 10.449935913085938\n",
            "0.605621337890625 10.05068842569987\n",
            "0.606964111328125 10.687908172607422\n",
            "0.608184814453125 10.019505818684896\n",
            "0.609405517578125 10.161226908365885\n",
            "0.610626220703125 10.613951365152994\n",
            "0.611846923828125 10.876426696777344\n",
            "0.613067626953125 10.671180725097656\n",
            "0.614410400390625 10.770712534586588\n",
            "0.615875244140625 10.785380045572916\n",
            "0.617462158203125 10.566763559977213\n",
            "0.619171142578125 10.766803741455078\n",
            "0.620880126953125 10.483250935872396\n",
            "0.622589111328125 10.186937967936197\n",
            "0.624298095703125 10.006880442301432\n",
            "0.625885009765625 10.457873026529947\n",
            "0.627349853515625 10.249374389648438\n",
            "0.628692626953125 10.595091501871744\n",
            "0.630035400390625 10.554790496826172\n",
            "0.631500244140625 10.2542724609375\n",
            "0.632965087890625 10.073780059814453\n",
            "0.634918212890625 10.981854756673178\n",
            "0.636871337890625 10.917274475097656\n",
            "0.638580322265625 10.364463806152344\n",
            "0.640167236328125 10.364049275716146\n",
            "0.641876220703125 10.746691385904947\n",
            "0.643585205078125 10.598060607910156\n",
            "0.645172119140625 10.363661448160807\n",
            "0.646881103515625 10.69586435953776\n",
            "0.648590087890625 10.582586924235025\n",
            "0.650054931640625 10.261184692382812\n",
            "0.651397705078125 10.499655405680338\n",
            "0.652862548828125 10.856011708577475\n",
            "0.654327392578125 10.7511838277181\n",
            "0.655670166015625 10.520924886067709\n",
            "0.657012939453125 10.526727040608725\n",
            "0.658355712890625 10.465011596679688\n",
            "0.659698486328125 10.410802205403646\n",
            "0.661163330078125 10.173871358235678\n",
            "0.663116455078125 10.76437250773112\n",
            "0.665069580078125 10.914360046386719\n",
            "0.667022705078125 10.730328877766928\n",
            "0.669219970703125 10.969290415445963\n",
            "0.671173095703125 10.338122049967447\n",
            "0.673126220703125 10.048423767089844\n",
            "0.675323486328125 10.4322878519694\n",
            "0.677276611328125 10.05899175008138\n",
            "0.678985595703125 10.091248830159506\n",
            "0.680450439453125 10.856576283772787\n",
            "0.681915283203125 10.235392252604166\n",
            "0.683380126953125 10.181434631347656\n",
            "0.684722900390625 10.49941889444987\n",
            "0.685943603515625 10.362908681233725\n",
            "0.687286376953125 10.76308822631836\n",
            "0.688629150390625 10.692582448323568\n",
            "0.689849853515625 10.826138814290365\n",
            "0.691070556640625 10.159786224365234\n",
            "0.692413330078125 10.59756088256836\n",
            "0.693634033203125 10.23367182413737\n",
            "0.694854736328125 10.003030141194662\n",
            "0.696075439453125 10.066270192464193\n",
            "0.697296142578125 10.322737375895182\n",
            "0.698516845703125 10.807661692301432\n",
            "0.699615478515625 10.246095021565756\n",
            "0.700714111328125 10.897998809814453\n",
            "0.701690673828125 10.22726821899414\n",
            "0.702667236328125 10.054373423258463\n",
            "0.703643798828125 10.115030924479166\n",
            "0.704742431640625 10.888238271077475\n",
            "0.705841064453125 10.656440734863281\n",
            "0.707061767578125 10.700856526692709\n",
            "0.708282470703125 10.165081024169922\n",
            "0.709625244140625 10.560662587483725\n",
            "0.711090087890625 10.788047790527344\n",
            "0.712554931640625 10.593209584554037\n",
            "0.713897705078125 10.651496887207031\n",
            "0.715362548828125 10.84812037150065\n",
            "0.716827392578125 10.84985605875651\n",
            "0.718292236328125 10.237581888834635\n",
            "0.719757080078125 10.28534189860026\n",
            "0.721099853515625 10.551653544108072\n",
            "0.722320556640625 10.328079223632812\n",
            "0.723785400390625 10.379544576009115\n",
            "0.725372314453125 10.495100657145182\n",
            "0.727325439453125 10.393202463785807\n",
            "0.729034423828125 10.7703857421875\n",
            "0.730621337890625 10.489420572916666\n",
            "0.732086181640625 10.045602162679037\n",
            "0.733551025390625 10.744012196858725\n",
            "0.735015869140625 10.697123209635416\n",
            "0.736480712890625 10.592628479003906\n",
            "0.737945556640625 10.883861541748047\n",
            "0.739288330078125 10.695269266764322\n",
            "0.740386962890625 10.164255777994791\n",
            "0.741485595703125 10.542291005452475\n",
            "0.742706298828125 10.8421999613444\n",
            "0.743927001953125 10.980002085367838\n",
            "0.745147705078125 10.929556528727213\n",
            "0.746368408203125 10.700916290283203\n",
            "0.747467041015625 10.805288950602213\n",
            "0.748443603515625 10.903008778889975\n",
            "0.749298095703125 10.059492746988932\n",
            "0.750152587890625 10.123372395833334\n",
            "0.751129150390625 10.534001668294271\n",
            "0.752227783203125 10.720344543457031\n",
            "0.753448486328125 10.82406489054362\n",
            "0.754425048828125 10.436171213785807\n",
            "0.755279541015625 10.875446319580078\n",
            "0.756134033203125 10.535601298014322\n",
            "0.756988525390625 10.365208943684896\n",
            "0.757843017578125 10.770753224690756\n",
            "0.758697509765625 10.59854507446289\n",
            "0.759552001953125 10.367201487223307\n",
            "0.760406494140625 10.479625701904297\n",
            "0.761138916015625 10.511402130126953\n",
            "0.761871337890625 10.718077341715494\n",
            "0.762603759765625 10.624123891194662\n",
            "0.763336181640625 10.49636713663737\n",
            "0.764068603515625 10.851676940917969\n",
            "0.764678955078125 10.043941497802734\n",
            "0.765289306640625 10.200972239176432\n",
            "0.765899658203125 10.338572184244791\n",
            "0.766510009765625 10.582839965820312\n",
            "0.767120361328125 10.238260904947916\n",
            "0.767730712890625 10.195360819498697\n",
            "0.768402099609375 10.57470448811849\n",
            "0.769134521484375 10.605626424153646\n",
            "0.769989013671875 10.376083374023438\n",
            "0.771209716796875 10.73214594523112\n",
            "0.772430419921875 10.959078470865885\n",
            "0.773895263671875 10.750848134358725\n",
            "0.775115966796875 10.388458251953125\n",
            "0.776336669921875 10.074129740397135\n",
            "0.777557373046875 10.682640075683594\n",
            "0.778656005859375 10.604409535725912\n",
            "0.779632568359375 10.199665069580078\n",
            "0.780609130859375 10.742811838785807\n",
            "0.781463623046875 10.624656677246094\n",
            "0.782196044921875 10.031265258789062\n",
            "0.783050537109375 10.251569112141928\n",
            "0.784027099609375 10.918460845947266\n",
            "0.785125732421875 10.804796854654947\n",
            "0.786346435546875 10.882467905680338\n",
            "0.787445068359375 10.452012379964193\n",
            "0.788421630859375 10.00848134358724\n",
            "0.789642333984375 10.881093343098959\n",
            "0.790863037109375 10.47475560506185\n",
            "0.791961669921875 10.399322509765625\n",
            "0.793060302734375 10.70791498819987\n",
            "0.794158935546875 10.522228240966797\n",
            "0.795257568359375 10.40639623006185\n",
            "0.796234130859375 10.690163930257162\n",
            "0.797088623046875 10.409112294514975\n",
            "0.797943115234375 10.797589619954428\n",
            "0.798797607421875 10.844095865885416\n",
            "0.799652099609375 10.438054402669271\n",
            "0.800628662109375 10.677581787109375\n",
            "0.801483154296875 10.184521993001303\n",
            "0.802337646484375 10.127217610677084\n",
            "0.803192138671875 10.641337076822916\n",
            "0.804046630859375 10.608033498128256\n",
            "0.804901123046875 10.778133392333984\n",
            "0.805572509765625 10.748275756835938\n",
            "0.806182861328125 10.749402364095053\n",
            "0.806732177734375 10.736990610758463\n",
            "0.807342529296875 10.81967290242513\n",
            "0.807952880859375 10.644437154134115\n",
            "0.808563232421875 10.315970102945963\n",
            "0.809173583984375 10.649911244710287\n",
            "0.809722900390625 10.436105092366537\n",
            "0.810272216796875 10.264742533365885\n",
            "0.810882568359375 10.408653259277344\n",
            "0.811553955078125 10.602914174397787\n",
            "0.812286376953125 10.938103993733725\n",
            "0.813018798828125 10.47567621866862\n",
            "0.813751220703125 10.550636291503906\n",
            "0.814361572265625 10.186285654703775\n",
            "0.814971923828125 10.434888203938803\n",
            "0.815704345703125 10.616596221923828\n",
            "0.816436767578125 10.297999064127604\n",
            "0.817169189453125 10.422396341959635\n",
            "0.817901611328125 10.271919250488281\n",
            "0.818756103515625 10.828773498535156\n",
            "0.819610595703125 10.976008097330729\n",
            "0.820404052734375 10.51888656616211\n",
            "0.821258544921875 10.787911732991537\n",
            "0.822113037109375 10.890974680582682\n",
            "0.822967529296875 10.983383178710938\n",
            "0.823822021484375 10.210968017578125\n",
            "0.824798583984375 10.635941823323568\n",
            "0.825775146484375 10.530773162841797\n",
            "0.826507568359375 10.902325948079428\n",
            "0.827117919921875 10.548970540364584\n",
            "0.827667236328125 10.701543172200521\n",
            "0.828155517578125 10.00787353515625\n",
            "0.828704833984375 10.403579711914062\n",
            "0.829254150390625 10.444718678792318\n",
            "0.829803466796875 10.677850087483725\n",
            "0.830352783203125 10.231950124104818\n",
            "0.830963134765625 10.932640075683594\n",
            "0.831512451171875 10.395366668701172\n",
            "0.832061767578125 10.52346420288086\n",
            "0.832611083984375 10.362506866455078\n",
            "0.833221435546875 10.263561248779297\n",
            "0.833831787109375 10.100840250651041\n",
            "0.834442138671875 10.395521799723307\n",
            "0.835052490234375 10.70596694946289\n",
            "0.835601806640625 10.473735809326172\n",
            "0.836090087890625 10.030521392822266\n",
            "0.836700439453125 10.95077641805013\n",
            "0.837310791015625 10.256197611490885\n",
            "0.837921142578125 10.27899169921875\n",
            "0.838531494140625 10.312000274658203\n",
            "0.839141845703125 10.038711547851562\n",
            "0.839813232421875 10.318778991699219\n",
            "0.840545654296875 10.710121154785156\n",
            "0.841400146484375 10.602185567220053\n",
            "0.842193603515625 10.534940083821615\n",
            "0.842926025390625 10.465684254964193\n",
            "0.843597412109375 10.347962697347006\n",
            "0.844207763671875 10.321357727050781\n",
            "0.844818115234375 10.526504516601562\n",
            "0.845428466796875 10.160535176595053\n",
            "0.846038818359375 10.707308451334635\n",
            "0.846588134765625 10.387402852376303\n",
            "0.847137451171875 10.883769989013672\n",
            "0.847625732421875 10.569798787434896\n",
            "0.848114013671875 10.323131561279297\n",
            "0.848602294921875 10.805357615152994\n",
            "0.849029541015625 10.147552490234375\n",
            "0.849517822265625 10.48012669881185\n",
            "0.850067138671875 10.70489501953125\n",
            "0.850616455078125 10.47613525390625\n",
            "0.851165771484375 10.691394805908203\n",
            "0.851654052734375 10.638317108154297\n",
            "0.852081298828125 10.140583038330078\n",
            "0.852569580078125 10.614092508951822\n",
            "0.853118896484375 10.90920893351237\n",
            "0.853668212890625 10.428295135498047\n",
            "0.854278564453125 10.157697041829428\n",
            "0.854888916015625 10.031997680664062\n",
            "0.855560302734375 10.947333017985025\n",
            "0.856292724609375 10.754183451334635\n",
            "0.857025146484375 10.664070129394531\n",
            "0.857696533203125 10.785245259602865\n",
            "0.858367919921875 10.970996856689453\n",
            "0.859039306640625 10.998128255208334\n",
            "0.859710693359375 10.985722859700521\n",
            "0.860321044921875 10.000550587972006\n",
            "0.860931396484375 10.549119313557943\n",
            "0.86151123046875 10.497001647949219\n",
            "0.862060546875 10.362787882486979\n",
            "0.86260986328125 10.801142374674479\n",
            "0.8631591796875 10.136713663736979\n",
            "0.86376953125 10.73684310913086\n",
            "0.8643798828125 10.676844278971354\n",
            "0.864990234375 10.61477279663086\n",
            "0.8656005859375 10.76934814453125\n",
            "0.86614990234375 10.35037104288737\n",
            "0.86669921875 10.242992401123047\n",
            "0.8673095703125 10.884329477945963\n",
            "0.867919921875 10.04248301188151\n",
            "0.86859130859375 10.822779337565104\n",
            "0.8692626953125 10.134699503580729\n",
            "0.8699951171875 10.228580474853516\n",
            "0.8707275390625 10.09981918334961\n",
            "0.87152099609375 10.555470784505209\n",
            "0.87237548828125 10.463429768880209\n",
            "0.87322998046875 10.335210164388021\n",
            "0.87408447265625 10.039737701416016\n",
            "0.87493896484375 10.382623036702475\n",
            "0.87579345703125 10.770403544108072\n",
            "0.87664794921875 10.689004262288412\n",
            "0.87750244140625 10.682515462239584\n",
            "0.87835693359375 10.443419138590494\n",
            "0.87921142578125 10.123804728190104\n",
            "0.880126953125 10.556065877278646\n",
            "0.8809814453125 10.0345458984375\n",
            "0.8819580078125 10.845102945963541\n",
            "0.8829345703125 10.8988037109375\n",
            "0.8839111328125 10.22735850016276\n",
            "0.885009765625 10.340694427490234\n",
            "0.8861083984375 10.703397115071615\n",
            "0.8870849609375 10.281963348388672\n",
            "0.8880615234375 10.593544006347656\n",
            "0.8890380859375 10.48931630452474\n",
            "0.8900146484375 10.46087646484375\n",
            "0.8909912109375 10.858778635660807\n",
            "0.8919677734375 10.88620376586914\n",
            "0.89306640625 10.936906178792318\n",
            "0.89404296875 10.063961029052734\n",
            "0.8951416015625 10.3115603129069\n",
            "0.8963623046875 10.999201456705729\n",
            "0.8974609375 10.615951538085938\n",
            "0.8984375 10.69739023844401\n",
            "0.8994140625 10.01617685953776\n",
            "0.9005126953125 10.896116892496744\n",
            "0.9014892578125 10.089132944742838\n",
            "0.9024658203125 10.609327952067057\n",
            "0.9034423828125 10.723526000976562\n",
            "0.904296875 10.343151092529297\n",
            "0.90509033203125 10.414105733235678\n",
            "0.90582275390625 10.037620544433594\n",
            "0.90655517578125 10.905001322428385\n",
            "0.90716552734375 10.506979624430338\n",
            "0.90771484375 10.105262756347656\n",
            "0.9083251953125 10.995737711588541\n",
            "0.908935546875 10.862045288085938\n",
            "0.9095458984375 10.67099634806315\n",
            "0.91015625 10.657103220621744\n",
            "0.9107666015625 10.666793823242188\n",
            "0.911376953125 10.77145512898763\n",
            "0.9119873046875 10.872295379638672\n",
            "0.91259765625 10.72927729288737\n",
            "0.9132080078125 10.044113159179688\n",
            "0.9139404296875 10.430508931477865\n",
            "0.914794921875 10.692474365234375\n",
            "0.9156494140625 10.246429443359375\n",
            "0.91650390625 10.688491821289062\n",
            "0.9173583984375 10.658774058024088\n",
            "0.918212890625 10.582445780436197\n",
            "0.9190673828125 10.164412180582682\n",
            "0.9200439453125 10.595413208007812\n",
            "0.921142578125 10.42294692993164\n",
            "0.92236328125 10.725467681884766\n",
            "0.9237060546875 10.74588139851888\n",
            "0.9251708984375 10.444170633951822\n",
            "0.927001953125 10.476516723632812\n",
            "0.928955078125 10.835210164388021\n",
            "0.930908203125 10.4182980855306\n",
            "0.932861328125 10.698613484700521\n",
            "0.9345703125 10.024242401123047\n",
            "0.936279296875 10.072135925292969\n",
            "0.938232421875 10.956565856933594\n",
            "0.940185546875 10.314866383870443\n",
            "0.9423828125 10.35733159383138\n",
            "0.94482421875 10.781002044677734\n",
            "0.947265625 10.592962900797525\n",
            "0.94970703125 10.518971761067709\n",
            "0.951904296875 10.199166615804037\n",
            "0.953857421875 10.876422882080078\n",
            "0.955810546875 10.496931711832682\n",
            "0.957763671875 10.623245239257812\n",
            "0.95947265625 10.091318766276041\n",
            "0.96142578125 10.90835189819336\n",
            "0.96337890625 10.61224110921224\n",
            "0.965576171875 10.93938954671224\n",
            "0.9676513671875 10.556500752766928\n",
            "0.9696044921875 10.155042012532553\n",
            "0.9718017578125 10.63103993733724\n",
            "0.9744873046875 10.82610829671224\n",
            "0.9774169921875 10.404048919677734\n",
            "0.9803466796875 10.732200622558594\n",
            "0.9830322265625 10.649542490641275\n",
            "0.9854736328125 10.016700744628906\n",
            "0.9881591796875 10.49704615275065\n",
            "0.9906005859375 10.000295003255209\n",
            "0.9932861328125 10.693272908528646\n",
            "0.9959716796875 10.343118031819662\n",
            "0.9989013671875 10.212064107259115\n",
            "1.0032958984375 10.580084482828775\n",
            "[MoviePy] >>>> Building video circular.mp4\n",
            "[MoviePy] Writing video circular.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 533/533 [00:06<00:00, 80.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: circular.mp4 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlBxQoUmDkc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9eb12858-7241-42f4-d5f6-ebceb6de6201"
      },
      "source": [
        "%ls\n",
        "%cp circular.mp4 '/content/drive/My Drive/twist_moe/videos'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " adaptive.py                      \u001b[0m\u001b[01;32mREADME.md\u001b[0m*\n",
            " \u001b[01;32malign_images.py\u001b[0m*                 requirements.txt\n",
            " circular.mp4                     \u001b[01;34mrobust_loss\u001b[0m/\n",
            " \u001b[01;32mdataset_tool.py\u001b[0m*                 \u001b[01;32mrun_generator.py\u001b[0m*\n",
            " \u001b[01;34mdnnlib\u001b[0m/                          \u001b[01;32mrun_metrics.py\u001b[0m*\n",
            " \u001b[01;32mDockerfile\u001b[0m*                      \u001b[01;32mrun_projector.py\u001b[0m*\n",
            " \u001b[01;34mdocs\u001b[0m/                            run_training.py\n",
            " \u001b[01;32mencode_images.py\u001b[0m*                runway_model.py\n",
            " \u001b[01;34mencoder\u001b[0m/                         runway.yml\n",
            " fake_art_portrait.jpg            StyleGAN_Encoder_Tutorial.ipynb\n",
            " \u001b[01;34mffhq_dataset\u001b[0m/                    swa.py\n",
            " \u001b[01;32mLICENSE.txt\u001b[0m*                     \u001b[01;32mtest_nvcc\u001b[0m*\n",
            " \u001b[01;34mmetrics\u001b[0m/                         \u001b[01;32mtest_nvcc.cu\u001b[0m*\n",
            " \u001b[01;34mmodels\u001b[0m/                          \u001b[01;34mtraining\u001b[0m/\n",
            " \u001b[01;32mpretrained_networks.py\u001b[0m*          \u001b[01;32mtrain_resnet.py\u001b[0m*\n",
            "'Process WikiArt Dataset.ipynb'  'WikiArt Example Generation.ipynb'\n",
            " \u001b[01;32mprojector.py\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-HTjbmIDseN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}